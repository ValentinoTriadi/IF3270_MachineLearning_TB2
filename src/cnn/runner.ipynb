{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "789ba4f2",
   "metadata": {},
   "source": [
    "# Keras Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "48e5da08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Library\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..', '..')))\n",
    "from src.cnn.keras_model import KerasModel\n",
    "from src.cnn.cnn import CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e90dc616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "RANDOM_SEED = 42\n",
    "RESULTS_BASE_DIR = \"output/keras\"\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2c1cdfba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading CIFAR-10 dataset for training and testing\n",
      "Data loaded: train shape: (50000, 32, 32, 3), input_shape for model: (32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(RESULTS_BASE_DIR):\n",
    "    os.makedirs(RESULTS_BASE_DIR, exist_ok=True)\n",
    "    print(f\"Created directory for training results: {RESULTS_BASE_DIR}\")\n",
    "\n",
    "print(\"\\nLoading CIFAR-10 dataset for training and testing\")\n",
    "(x_train_keras, y_train_keras), (x_test_keras, y_test_keras) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "input_shape_global = x_train_keras.shape[1:]\n",
    "\n",
    "# Used for softmax in Dense Layer for the Keras\n",
    "num_classes_global = 10\n",
    "\n",
    "print(f\"Data loaded: train shape: {x_train_keras.shape}, input_shape for model: {input_shape_global}\")\n",
    "\n",
    "standard_dense_config_train = [{'units': 128, 'dropout': 0.5}]\n",
    "standard_global_pooling_train = 'global_avg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a708a259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It defines the function to run training experiments\n",
    "def run_experiment_set(experiment_group_name, model_configs_list, input_shape, num_classes, x_train_full_data, y_train_full_data, x_test_data, y_test_data):\n",
    "    print(f\"\\n{'='*20} Starting TRAINING Experiment Group: {experiment_group_name} {'='*20}\")\n",
    "    group_results = []\n",
    "    \n",
    "    shared_model_handler_for_data = KerasModel(input_shape=input_shape, num_class=num_classes, random_seed=RANDOM_SEED)\n",
    "    \n",
    "    shared_model_handler_for_data.preprocess_data(\n",
    "        x_train_full_data, y_train_full_data, x_test_data, y_test_data\n",
    "    )\n",
    "\n",
    "    for config_details in model_configs_list:\n",
    "        model_name = config_details['name']\n",
    "        model_params = config_details['params']\n",
    "\n",
    "        print(f\"\\n--- Training Configuration: {model_name} ---\")\n",
    "        \n",
    "        current_model_handler = KerasModel(input_shape=input_shape, num_class=num_classes, random_seed=RANDOM_SEED)\n",
    "        \n",
    "        current_model_handler.x_train = shared_model_handler_for_data.x_train\n",
    "        current_model_handler.y_train = shared_model_handler_for_data.y_train\n",
    "        current_model_handler.x_val = shared_model_handler_for_data.x_val\n",
    "        current_model_handler.y_val = shared_model_handler_for_data.y_val\n",
    "        current_model_handler.x_test_processed = shared_model_handler_for_data.x_test_processed\n",
    "        current_model_handler.y_test_processed = shared_model_handler_for_data.y_test_processed\n",
    "\n",
    "        current_model_handler.define_model(\n",
    "            model_name=model_name,\n",
    "            conv_blocks_config=model_params['conv_blocks_config'],\n",
    "            global_pooling_type=model_params['global_pooling_type'],\n",
    "            dense_layers_config=model_params['dense_layers_config']\n",
    "        )\n",
    "        current_model_handler.compile_model()\n",
    "        \n",
    "        current_model_handler.train_model(epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1)\n",
    "        \n",
    "        loss, acc, f1 = current_model_handler.evaluate_model(verbose=0)\n",
    "        \n",
    "        weights_path = os.path.join(RESULTS_BASE_DIR, experiment_group_name, model_name, f\"{model_name}_weights.weights.h5\")\n",
    "        current_model_handler.save_model_weights(weights_path) \n",
    "        \n",
    "        current_model_handler.plot_training_history(experiment_group_name, model_name, base_save_path=RESULTS_BASE_DIR)\n",
    "        \n",
    "        group_results.append({\n",
    "            'model_name': model_name, 'f1_score': f1, 'accuracy': acc,\n",
    "            'loss': loss, 'config_params': model_params\n",
    "        })\n",
    "\n",
    "    sorted_results = sorted(group_results, key=lambda x: x['f1_score'], reverse=True)\n",
    "    for res in sorted_results:\n",
    "        print(f\"Model: {res['model_name']}, F1-Score: {res['f1_score']:.4f}, Accuracy: {res['accuracy']:.4f}\")\n",
    "\n",
    "    return sorted_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "39b0e100",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_configurations = []\n",
    "experiments_to_run_grouped = {}\n",
    "all_training_results = {}\n",
    "\n",
    "\n",
    "if 'all_individual_training_runs_summary' not in locals(): \n",
    "    all_individual_training_runs_summary = {}\n",
    "\n",
    "def read_training_config(group_configs):\n",
    "    \"\"\"\n",
    "    Processes a list of model configurations for a specific experiment group.\n",
    "    For each model configuration in the list:\n",
    "    - Checks if weights exist.\n",
    "    - If not, calls run_experiment_set to train that single model.\n",
    "    \"\"\"\n",
    "    if not isinstance(group_configs, list):\n",
    "        print(f\"ERROR in read_training_config: Expected a list of configurations, but got {type(group_configs)}\")\n",
    "        return\n",
    "\n",
    "    for single_model_config_dict in group_configs:\n",
    "        model_name = single_model_config_dict['name']\n",
    "\n",
    "        experiment_group = single_model_config_dict['experiment_group']\n",
    "        model_params = single_model_config_dict['params'] # The actual architecture\n",
    "\n",
    "        print(f\"\\nChecking/Processing config: '{model_name}' in group '{experiment_group}'\")\n",
    "        \n",
    "        expected_weights_path = os.path.join(RESULTS_BASE_DIR, experiment_group, model_name, f\"{model_name}_weights.weights.h5\")\n",
    "        \n",
    "        if os.path.exists(expected_weights_path):\n",
    "            print(f\"    Weights for '{model_name}' already exist at '{expected_weights_path}'. Skipping training.\")\n",
    "            all_individual_training_runs_summary[model_name] = {\n",
    "                'status': 'skipped_weights_exist', \n",
    "                'weights_path': expected_weights_path,\n",
    "                'experiment_group': experiment_group \n",
    "            }\n",
    "        else:\n",
    "            print(f\"    Weights for '{model_name}' NOT found. Proceeding with training for this model...\")\n",
    "        \n",
    "            config_for_runner = [{'name': model_name, 'params': model_params}]\n",
    "    \n",
    "            individual_run_results_list = run_experiment_set(\n",
    "                experiment_group_name=experiment_group, \n",
    "                model_configs_list=config_for_runner, \n",
    "                input_shape=input_shape_global,\n",
    "                num_classes=num_classes_global,\n",
    "                x_train_full_data=x_train_keras,\n",
    "                y_train_full_data=y_train_keras,\n",
    "                x_test_data=x_test_keras,        \n",
    "                y_test_data=y_test_keras         \n",
    "            )\n",
    "            # run_experiment_set returns a list of results, even for one model\n",
    "            if individual_run_results_list:\n",
    "                all_individual_training_runs_summary[model_name] = individual_run_results_list[0]\n",
    "            \n",
    "                if 'experiment_group' not in all_individual_training_runs_summary[model_name]:\n",
    "                     all_individual_training_runs_summary[model_name]['experiment_group'] = experiment_group\n",
    "            else:\n",
    "                all_individual_training_runs_summary[model_name] = {\n",
    "                    'experiment_group': experiment_group\n",
    "                }\n",
    "    print(f\"Finished processing group of configurations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "72a04a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking/Processing config: 'A1_1_ConvBlock' in group 'A_Jumlah_Layer_Konvolusi'\n",
      "    Weights for 'A1_1_ConvBlock' already exist at 'output/keras\\A_Jumlah_Layer_Konvolusi\\A1_1_ConvBlock\\A1_1_ConvBlock_weights.weights.h5'. Skipping training.\n",
      "\n",
      "Checking/Processing config: 'A2_2_ConvBlocks' in group 'A_Jumlah_Layer_Konvolusi'\n",
      "    Weights for 'A2_2_ConvBlocks' already exist at 'output/keras\\A_Jumlah_Layer_Konvolusi\\A2_2_ConvBlocks\\A2_2_ConvBlocks_weights.weights.h5'. Skipping training.\n",
      "\n",
      "Checking/Processing config: 'A3_3_ConvBlocks' in group 'A_Jumlah_Layer_Konvolusi'\n",
      "    Weights for 'A3_3_ConvBlocks' already exist at 'output/keras\\A_Jumlah_Layer_Konvolusi\\A3_3_ConvBlocks\\A3_3_ConvBlocks_weights.weights.h5'. Skipping training.\n",
      "Finished processing group of configurations\n"
     ]
    }
   ],
   "source": [
    "# Training A (Comparing in Jumlah layer Konvolusi)\n",
    "group_A_name_train = \"A_Jumlah_Layer_Konvolusi\"\n",
    "\n",
    "Conv1 = [{'filters': 32, 'kernel_size': (3,3), 'conv_layers_in_block': 1, 'pooling_type': 'max', 'dropout_after_pool': 0.25}]\n",
    "\n",
    "Conv2 = [{'filters': 32, 'kernel_size': (3,3), 'conv_layers_in_block': 1, 'pooling_type': 'max', 'dropout_after_pool': 0.25},\n",
    "            {'filters': 64, 'kernel_size': (3,3), 'conv_layers_in_block': 1, 'pooling_type': 'max', 'dropout_after_pool': 0.25}]\n",
    "Conv3 = [ {'filters': 32, 'kernel_size': (3,3), 'conv_layers_in_block': 1, 'pooling_type': 'max', 'dropout_after_pool': 0.25},\n",
    "            {'filters': 64, 'kernel_size': (3,3), 'conv_layers_in_block': 1, 'pooling_type': 'max', 'dropout_after_pool': 0.25},\n",
    "            {'filters': 128, 'kernel_size': (3,3), 'conv_layers_in_block': 1, 'pooling_type': 'max', 'dropout_after_pool': 0.25}]\n",
    "\n",
    "training_A_Config = [\n",
    "    {'name': 'A1_1_ConvBlock', 'experiment_group': group_A_name_train, 'params': {\n",
    "        'conv_blocks_config': Conv1,\n",
    "        'global_pooling_type': standard_global_pooling_train, 'dense_layers_config': standard_dense_config_train}},\n",
    "    {'name': 'A2_2_ConvBlocks', 'experiment_group': group_A_name_train, 'params': {\n",
    "        'conv_blocks_config':Conv2,\n",
    "        'global_pooling_type': standard_global_pooling_train, 'dense_layers_config': standard_dense_config_train}},\n",
    "    {'name': 'A3_3_ConvBlocks', 'experiment_group': group_A_name_train, 'params': {\n",
    "        'conv_blocks_config': Conv3,\n",
    "        'global_pooling_type': standard_global_pooling_train, 'dense_layers_config': standard_dense_config_train}},\n",
    "]\n",
    "\n",
    "training_configurations.extend(training_A_Config)\n",
    "read_training_config(training_A_Config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d6ae2320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking/Processing config: 'A1_1_ConvBlock' in group 'A_Jumlah_Layer_Konvolusi'\n",
      "    Weights for 'A1_1_ConvBlock' already exist at 'output/keras\\A_Jumlah_Layer_Konvolusi\\A1_1_ConvBlock\\A1_1_ConvBlock_weights.weights.h5'. Skipping training.\n",
      "\n",
      "Checking/Processing config: 'A2_2_ConvBlocks' in group 'A_Jumlah_Layer_Konvolusi'\n",
      "    Weights for 'A2_2_ConvBlocks' already exist at 'output/keras\\A_Jumlah_Layer_Konvolusi\\A2_2_ConvBlocks\\A2_2_ConvBlocks_weights.weights.h5'. Skipping training.\n",
      "\n",
      "Checking/Processing config: 'A3_3_ConvBlocks' in group 'A_Jumlah_Layer_Konvolusi'\n",
      "    Weights for 'A3_3_ConvBlocks' already exist at 'output/keras\\A_Jumlah_Layer_Konvolusi\\A3_3_ConvBlocks\\A3_3_ConvBlocks_weights.weights.h5'. Skipping training.\n",
      "\n",
      "Checking/Processing config: 'B1_Filters_16_32' in group 'B_Banyak_Filter'\n",
      "    Weights for 'B1_Filters_16_32' already exist at 'output/keras\\B_Banyak_Filter\\B1_Filters_16_32\\B1_Filters_16_32_weights.weights.h5'. Skipping training.\n",
      "\n",
      "Checking/Processing config: 'B2_Filters_32_64' in group 'B_Banyak_Filter'\n",
      "    Weights for 'B2_Filters_32_64' already exist at 'output/keras\\B_Banyak_Filter\\B2_Filters_32_64\\B2_Filters_32_64_weights.weights.h5'. Skipping training.\n",
      "\n",
      "Checking/Processing config: 'B3_Filters_64_128' in group 'B_Banyak_Filter'\n",
      "    Weights for 'B3_Filters_64_128' already exist at 'output/keras\\B_Banyak_Filter\\B3_Filters_64_128\\B3_Filters_64_128_weights.weights.h5'. Skipping training.\n",
      "Finished processing group of configurations\n"
     ]
    }
   ],
   "source": [
    "# Training B (Comparing the amount of Filter)\n",
    "group_B_name_train = \"B_Banyak_Filter\"\n",
    "\n",
    "def create_conv_forB(filters_list):\n",
    "    return [{'filters': filters_list[0], 'kernel_size': (3,3), 'conv_layers_in_block': 1, 'pooling_type': 'max', 'dropout_after_pool': 0.25},\n",
    "            {'filters': filters_list[1], 'kernel_size': (3,3), 'conv_layers_in_block': 1, 'pooling_type': 'max', 'dropout_after_pool': 0.25}]\n",
    "\n",
    "training_B_Config = [\n",
    "    {'name': 'B1_Filters_16_32', 'experiment_group': group_B_name_train, 'params': \n",
    "     {'conv_blocks_config': create_conv_forB([16, 32]), 'global_pooling_type': standard_global_pooling_train, 'dense_layers_config': standard_dense_config_train}},\n",
    "    {'name': 'B2_Filters_32_64', 'experiment_group': group_B_name_train, 'params': \n",
    "     {'conv_blocks_config': create_conv_forB([32, 64]), 'global_pooling_type': standard_global_pooling_train, 'dense_layers_config': standard_dense_config_train}},\n",
    "    {'name': 'B3_Filters_64_128', 'experiment_group': group_B_name_train, 'params': \n",
    "     {'conv_blocks_config': create_conv_forB([64, 128]), 'global_pooling_type': standard_global_pooling_train, 'dense_layers_config': standard_dense_config_train}},\n",
    "]\n",
    "\n",
    "training_configurations.extend(training_B_Config)\n",
    "read_training_config(training_configurations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2571adfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking/Processing config: 'A1_1_ConvBlock' in group 'A_Jumlah_Layer_Konvolusi'\n",
      "    Weights for 'A1_1_ConvBlock' already exist at 'output/keras\\A_Jumlah_Layer_Konvolusi\\A1_1_ConvBlock\\A1_1_ConvBlock_weights.weights.h5'. Skipping training.\n",
      "\n",
      "Checking/Processing config: 'A2_2_ConvBlocks' in group 'A_Jumlah_Layer_Konvolusi'\n",
      "    Weights for 'A2_2_ConvBlocks' already exist at 'output/keras\\A_Jumlah_Layer_Konvolusi\\A2_2_ConvBlocks\\A2_2_ConvBlocks_weights.weights.h5'. Skipping training.\n",
      "\n",
      "Checking/Processing config: 'A3_3_ConvBlocks' in group 'A_Jumlah_Layer_Konvolusi'\n",
      "    Weights for 'A3_3_ConvBlocks' already exist at 'output/keras\\A_Jumlah_Layer_Konvolusi\\A3_3_ConvBlocks\\A3_3_ConvBlocks_weights.weights.h5'. Skipping training.\n",
      "\n",
      "Checking/Processing config: 'B1_Filters_16_32' in group 'B_Banyak_Filter'\n",
      "    Weights for 'B1_Filters_16_32' already exist at 'output/keras\\B_Banyak_Filter\\B1_Filters_16_32\\B1_Filters_16_32_weights.weights.h5'. Skipping training.\n",
      "\n",
      "Checking/Processing config: 'B2_Filters_32_64' in group 'B_Banyak_Filter'\n",
      "    Weights for 'B2_Filters_32_64' already exist at 'output/keras\\B_Banyak_Filter\\B2_Filters_32_64\\B2_Filters_32_64_weights.weights.h5'. Skipping training.\n",
      "\n",
      "Checking/Processing config: 'B3_Filters_64_128' in group 'B_Banyak_Filter'\n",
      "    Weights for 'B3_Filters_64_128' already exist at 'output/keras\\B_Banyak_Filter\\B3_Filters_64_128\\B3_Filters_64_128_weights.weights.h5'. Skipping training.\n",
      "\n",
      "Checking/Processing config: 'C1_Kernel_2x2' in group 'C_Ukuran_Filter'\n",
      "    Weights for 'C1_Kernel_2x2' already exist at 'output/keras\\C_Ukuran_Filter\\C1_Kernel_2x2\\C1_Kernel_2x2_weights.weights.h5'. Skipping training.\n",
      "\n",
      "Checking/Processing config: 'C2_Kernel_3x3' in group 'C_Ukuran_Filter'\n",
      "    Weights for 'C2_Kernel_3x3' already exist at 'output/keras\\C_Ukuran_Filter\\C2_Kernel_3x3\\C2_Kernel_3x3_weights.weights.h5'. Skipping training.\n",
      "\n",
      "Checking/Processing config: 'C3_Kernel_5x5' in group 'C_Ukuran_Filter'\n",
      "    Weights for 'C3_Kernel_5x5' already exist at 'output/keras\\C_Ukuran_Filter\\C3_Kernel_5x5\\C3_Kernel_5x5_weights.weights.h5'. Skipping training.\n",
      "Finished processing group of configurations\n"
     ]
    }
   ],
   "source": [
    "# Training C (Comparing the Size of Kernel)\n",
    "group_C_name_train = \"C_Ukuran_Filter\"\n",
    "def create_conv_forC(kernel_sizes_list):\n",
    "    return [{'filters': 64, 'kernel_size': kernel_sizes_list[0], 'conv_layers_in_block': 1, 'pooling_type': 'max', 'dropout_after_pool': 0.25},\n",
    "            {'filters': 64, 'kernel_size': kernel_sizes_list[1], 'conv_layers_in_block': 1, 'pooling_type': 'max', 'dropout_after_pool': 0.25}]\n",
    "\n",
    "training_C_config = [\n",
    "    {'name': 'C1_Kernel_2x2', 'experiment_group': group_C_name_train, 'params': \n",
    "     {'conv_blocks_config': create_conv_forC([(2,2), (2,2)]), 'global_pooling_type': standard_global_pooling_train, 'dense_layers_config': standard_dense_config_train}},\n",
    "    {'name': 'C2_Kernel_3x3', 'experiment_group': group_C_name_train, 'params': \n",
    "     {'conv_blocks_config': create_conv_forC([(3,3), (3,3)]), 'global_pooling_type': standard_global_pooling_train, 'dense_layers_config': standard_dense_config_train}},\n",
    "    {'name': 'C3_Kernel_5x5', 'experiment_group': group_C_name_train, 'params': \n",
    "     {'conv_blocks_config': create_conv_forC([(5,5), (5,5)]), 'global_pooling_type': standard_global_pooling_train, 'dense_layers_config': standard_dense_config_train}},\n",
    "]\n",
    "\n",
    "training_configurations.extend(training_C_config)\n",
    "read_training_config(training_configurations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1255e43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking/Processing config: 'D1_Pooling_Max' in group 'D_Jenis_Pooling'\n",
      "    Weights for 'D1_Pooling_Max' already exist at 'output/keras\\D_Jenis_Pooling\\D1_Pooling_Max\\D1_Pooling_Max_weights.weights.h5'. Skipping training.\n",
      "\n",
      "Checking/Processing config: 'D2_Pooling_Avg' in group 'D_Jenis_Pooling'\n",
      "    Weights for 'D2_Pooling_Avg' already exist at 'output/keras\\D_Jenis_Pooling\\D2_Pooling_Avg\\D2_Pooling_Avg_weights.weights.h5'. Skipping training.\n",
      "Finished processing group of configurations\n"
     ]
    }
   ],
   "source": [
    "# Training D (Comparing the type of the pooling)\n",
    "group_D_name_train = \"D_Jenis_Pooling\"\n",
    "def create_conv_forD(pooling_type_str):\n",
    "    return [{'filters': 32, 'kernel_size': (3,3), 'conv_layers_in_block': 1, 'pooling_type': pooling_type_str, 'pooling_size': (2,2), 'dropout_after_pool': 0.25},\n",
    "            {'filters': 64, 'kernel_size': (3,3), 'conv_layers_in_block': 1, 'pooling_type': pooling_type_str, 'pooling_size': (2,2), 'dropout_after_pool': 0.25}]\n",
    "training_D_config = [\n",
    "    {'name': 'D1_Pooling_Max', 'experiment_group': group_D_name_train, 'params': \n",
    "     {'conv_blocks_config': create_conv_forD('max'), 'global_pooling_type': standard_global_pooling_train, 'dense_layers_config': standard_dense_config_train}},\n",
    "    {'name': 'D2_Pooling_Avg', 'experiment_group': group_D_name_train, 'params': \n",
    "     {'conv_blocks_config': create_conv_forD('avg'), 'global_pooling_type': standard_global_pooling_train, 'dense_layers_config': standard_dense_config_train}},\n",
    "]\n",
    "\n",
    "training_configurations.extend(training_D_config)\n",
    "read_training_config(training_D_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4a0d2172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_keras_model_for_loading(model_name, input_s, num_c, architecture_config):\n",
    "    \"\"\"\n",
    "    Reconstructs a Keras model based on an architecture configuration.\n",
    "    This is used for loading weights \n",
    "    \"\"\"\n",
    "    conv_blocks_config = architecture_config['conv_blocks_config']\n",
    "    global_pooling_type = architecture_config['global_pooling_type']\n",
    "    dense_layers_config = architecture_config['dense_layers_config']\n",
    "\n",
    "    model_layers_list = [layers.Input(shape=input_s, name=\"input_layer\")]\n",
    "    \n",
    "    for i, block_config in enumerate(conv_blocks_config):\n",
    "        for j in range(block_config['conv_layers_in_block']):\n",
    "            model_layers_list.append(layers.Conv2D(\n",
    "                filters=block_config['filters'], kernel_size=block_config['kernel_size'],\n",
    "                activation='relu', \n",
    "                padding='same', name=f\"conv_block{i+1}_layer{j+1}\"\n",
    "            ))\n",
    "        if block_config['pooling_type'] == 'max':\n",
    "            model_layers_list.append(layers.MaxPooling2D(pool_size=block_config.get('pooling_size', (2,2)), name=f\"maxpool_block{i+1}\"))\n",
    "        elif block_config['pooling_type'] == 'avg':\n",
    "             model_layers_list.append(layers.AveragePooling2D(pool_size=block_config.get('pooling_size', (2,2)), name=f\"avgpool_block{i+1}\"))\n",
    "    \n",
    "    if global_pooling_type == 'global_avg': \n",
    "        model_layers_list.append(layers.GlobalAveragePooling2D(name=\"global_avg_pool_layer\"))\n",
    "\n",
    "    elif global_pooling_type == 'flatten': \n",
    "        model_layers_list.append(layers.Flatten(name=\"flatten_layer\"))\n",
    "    \n",
    "    for i, dense_config_item in enumerate(dense_layers_config):\n",
    "        model_layers_list.append(layers.Dense(dense_config_item['units'], activation='relu', name=f\"dense_layer{i+1}\"))\n",
    "            \n",
    "    model_layers_list.append(layers.Dense(num_c, activation='softmax', name=\"output_layer\"))\n",
    "    \n",
    "    keras_model = keras.Sequential(model_layers_list, name=model_name + \"_keras_loaded_for_inference\")\n",
    "    return keras_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2599a923",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_forward_propagation_comparison(\n",
    "    model_name_tag,\n",
    "    keras_architecture_config, \n",
    "    base_weights_dir_to_load, \n",
    "    experiment_group_for_weights,\n",
    "    x_test_full_keras_data,    \n",
    "    y_test_full_keras_data,    \n",
    "    input_shape_param,        \n",
    "    num_classes_param,        \n",
    "    num_samples_to_test=50 \n",
    "):\n",
    "    '''\n",
    "    This function used to compare the prediction between the keras and scratch\n",
    "    '''\n",
    "    print(f\"\\nProcessing Model: {model_name_tag} (from group: {experiment_group_for_weights})\")\n",
    "\n",
    "    results = {\n",
    "        'model_name': model_name_tag, 'f1_keras': None, 'f1_scratch': None,\n",
    "        'f1_difference': None, 'label_matches_ratio': None,\n",
    "        'mean_abs_prob_diff': None, 'status': 'Not Processed'\n",
    "    }\n",
    "\n",
    "    keras_weights_path = os.path.join(base_weights_dir_to_load, experiment_group_for_weights, model_name_tag, f\"{model_name_tag}_weights.weights.h5\")\n",
    "    \n",
    "    if not os.path.exists(keras_weights_path):\n",
    "        return results\n",
    "\n",
    "    print(f\"Reconstructing Keras model '{model_name_tag}' for inference...\")\n",
    "    keras_model_loaded = create_keras_model_for_loading(\n",
    "        model_name_tag, input_shape_param, num_classes_param, keras_architecture_config\n",
    "    )\n",
    "    try:\n",
    "        keras_model_loaded.load_weights(keras_weights_path)\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Failed to load Keras for {model_name_tag}. Error: {e}\")\n",
    "        return results\n",
    "\n",
    "    x_test_normalized_all = x_test_full_keras_data.astype(\"float32\") / 255.0\n",
    "    y_test_labels_all_flat = y_test_full_keras_data.flatten()\n",
    "    \n",
    "    actual_num_samples = min(num_samples_to_test, len(x_test_normalized_all))\n",
    "    x_test_subset = x_test_normalized_all[:actual_num_samples]\n",
    "    y_test_subset_labels = y_test_labels_all_flat[:actual_num_samples]\n",
    "    if actual_num_samples == 0:\n",
    "        print(\"ERROR : No S\")\n",
    "        return results\n",
    "    print(f\"Using {actual_num_samples} samples for prediction testing.\")\n",
    "\n",
    "    scratch_model_instance = CNN()\n",
    "    scratch_model_instance.load_keras_model(keras_model_loaded)\n",
    "\n",
    "    print(f\"Keras Prediction : \")\n",
    "    print()\n",
    "\n",
    "    keras_probabilities = keras_model_loaded.predict(x_test_subset, verbose=0)\n",
    "    keras_predictions = np.argmax(keras_probabilities, axis=1)\n",
    "    results['f1_keras'] = f1_score(y_test_subset_labels, keras_predictions, average='macro', zero_division=0)\n",
    "    print(f\"Keras F1-Score: {results['f1_keras']:.4f}\")\n",
    "\n",
    "    print(f\"CNN Scratch Prediction : \")\n",
    "    if scratch_model_instance.layers:\n",
    "        scratch_probabilities = scratch_model_instance.predict_batch(x_test_subset, model_name_tag)\n",
    "        scratch_predictions = np.argmax(scratch_probabilities, axis=1)\n",
    "        results['f1_scratch'] = f1_score(y_test_subset_labels, scratch_predictions, average='macro', zero_division=0)\n",
    "        print(f\"Scratch F1-Score: {results['f1_scratch']:.4f}\")\n",
    "    else:\n",
    "        print(\"Scratch model has no layers, skipping Scratch prediction.\")\n",
    "        return results \n",
    "\n",
    "    \n",
    "    if results['f1_keras'] is not None and results['f1_scratch'] is not None:\n",
    "        results['f1_difference'] = abs(results['f1_keras'] - results['f1_scratch'])\n",
    "        num_matching_labels = np.sum(keras_predictions == scratch_predictions)\n",
    "        results['label_matches_ratio'] = num_matching_labels / actual_num_samples\n",
    "        results['mean_abs_prob_diff'] = np.mean(np.abs(keras_probabilities - scratch_probabilities))\n",
    "\n",
    "        print(f\"F1-Score Difference: {results['f1_difference']:.6f}\")\n",
    "        print(f\"Label Match Ratio: {results['label_matches_ratio']:.4f}\")\n",
    "        print(f\"Mean Absolute Probability Difference: {results['mean_abs_prob_diff']:.6f}\")\n",
    "        \n",
    "        if results['f1_difference'] < 1e-3 and results['label_matches_ratio'] >= 0.99: \n",
    "            print(f\"Status: Success - Results Closely Match\")\n",
    "        else:\n",
    "            print(f\"Status: WARNING - Significant Difference in Results\") \n",
    "\n",
    "    print(f\"Finished processing Model: {model_name_tag}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c9fdcf35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total configurations adapted for forward-prop test: 11\n",
      "\n",
      "Starting forward propagation comparison for 11 model configurations\n",
      "\n",
      "Test Forward Prop for Model 1/11\n",
      "\n",
      "Processing Model: A1_1_ConvBlock (from group: A_Jumlah_Layer_Konvolusi)\n",
      "Reconstructing Keras model 'A1_1_ConvBlock' for inference...\n",
      "Using 50 samples for prediction testing.\n",
      "Load Keras Model \n",
      "Adding Conv2DLayer (kernel: (3, 3, 3, 32), stride: (1, 1), padding: same)\n",
      "Adding ReLULayer\n",
      "Adding MaxPooling2DLayer (pool_size: (2, 2), stride: (2, 2))\n",
      "Adding GlobalAveragePooling2DLayer\n",
      "Adding Dense Layer(weight: (32, 128))\n",
      "Adding ReLu\n",
      "Adding Dense Layer(weight: (128, 10))\n",
      "Adding SoftMax\n",
      "Keras Prediction : \n",
      "\n",
      "Keras F1-Score: 0.4405\n",
      "CNN Scratch Prediction : \n",
      "\n",
      "Starting Scratch Prediction for 'A1_1_ConvBlock' on 50 samples:\n",
      "Processing: 50/50 (100.0%)\n",
      "Batch prediction complete for 'A1_1_ConvBlock'.\n",
      "Total time: 7.47 seconds (0.149 sec/sample).\n",
      "Output array shape: (50, 10)\n",
      "\n",
      "Scratch F1-Score: 0.4405\n",
      "F1-Score Difference: 0.000000\n",
      "Label Match Ratio: 1.0000\n",
      "Mean Absolute Probability Difference: 0.000000\n",
      "Status: Success - Results Closely Match\n",
      "Finished processing Model: A1_1_ConvBlock\n",
      "\n",
      "Test Forward Prop for Model 2/11\n",
      "\n",
      "Processing Model: A2_2_ConvBlocks (from group: A_Jumlah_Layer_Konvolusi)\n",
      "Reconstructing Keras model 'A2_2_ConvBlocks' for inference...\n",
      "Using 50 samples for prediction testing.\n",
      "Load Keras Model \n",
      "Adding Conv2DLayer (kernel: (3, 3, 3, 32), stride: (1, 1), padding: same)\n",
      "Adding ReLULayer\n",
      "Adding MaxPooling2DLayer (pool_size: (2, 2), stride: (2, 2))\n",
      "Adding Conv2DLayer (kernel: (3, 3, 32, 64), stride: (1, 1), padding: same)\n",
      "Adding ReLULayer\n",
      "Adding MaxPooling2DLayer (pool_size: (2, 2), stride: (2, 2))\n",
      "Adding GlobalAveragePooling2DLayer\n",
      "Adding Dense Layer(weight: (64, 128))\n",
      "Adding ReLu\n",
      "Adding Dense Layer(weight: (128, 10))\n",
      "Adding SoftMax\n",
      "Keras Prediction : \n",
      "\n",
      "Keras F1-Score: 0.4768\n",
      "CNN Scratch Prediction : \n",
      "\n",
      "Starting Scratch Prediction for 'A2_2_ConvBlocks' on 50 samples:\n",
      "Processing: 50/50 (100.0%)\n",
      "Batch prediction complete for 'A2_2_ConvBlocks'.\n",
      "Total time: 11.80 seconds (0.236 sec/sample).\n",
      "Output array shape: (50, 10)\n",
      "\n",
      "Scratch F1-Score: 0.4768\n",
      "F1-Score Difference: 0.000000\n",
      "Label Match Ratio: 1.0000\n",
      "Mean Absolute Probability Difference: 0.000000\n",
      "Status: Success - Results Closely Match\n",
      "Finished processing Model: A2_2_ConvBlocks\n",
      "\n",
      "Test Forward Prop for Model 3/11\n",
      "\n",
      "Processing Model: A3_3_ConvBlocks (from group: A_Jumlah_Layer_Konvolusi)\n",
      "Reconstructing Keras model 'A3_3_ConvBlocks' for inference...\n",
      "Using 50 samples for prediction testing.\n",
      "Load Keras Model \n",
      "Adding Conv2DLayer (kernel: (3, 3, 3, 32), stride: (1, 1), padding: same)\n",
      "Adding ReLULayer\n",
      "Adding MaxPooling2DLayer (pool_size: (2, 2), stride: (2, 2))\n",
      "Adding Conv2DLayer (kernel: (3, 3, 32, 64), stride: (1, 1), padding: same)\n",
      "Adding ReLULayer\n",
      "Adding MaxPooling2DLayer (pool_size: (2, 2), stride: (2, 2))\n",
      "Adding Conv2DLayer (kernel: (3, 3, 64, 128), stride: (1, 1), padding: same)\n",
      "Adding ReLULayer\n",
      "Adding MaxPooling2DLayer (pool_size: (2, 2), stride: (2, 2))\n",
      "Adding GlobalAveragePooling2DLayer\n",
      "Adding Dense Layer(weight: (128, 128))\n",
      "Adding ReLu\n",
      "Adding Dense Layer(weight: (128, 10))\n",
      "Adding SoftMax\n",
      "Keras Prediction : \n",
      "\n",
      "Keras F1-Score: 0.6912\n",
      "CNN Scratch Prediction : \n",
      "\n",
      "Starting Scratch Prediction for 'A3_3_ConvBlocks' on 50 samples:\n",
      "Processing: 50/50 (100.0%)\n",
      "Batch prediction complete for 'A3_3_ConvBlocks'.\n",
      "Total time: 14.32 seconds (0.286 sec/sample).\n",
      "Output array shape: (50, 10)\n",
      "\n",
      "Scratch F1-Score: 0.6912\n",
      "F1-Score Difference: 0.000000\n",
      "Label Match Ratio: 1.0000\n",
      "Mean Absolute Probability Difference: 0.000000\n",
      "Status: Success - Results Closely Match\n",
      "Finished processing Model: A3_3_ConvBlocks\n",
      "\n",
      "Test Forward Prop for Model 4/11\n",
      "\n",
      "Processing Model: B1_Filters_16_32 (from group: B_Banyak_Filter)\n",
      "Reconstructing Keras model 'B1_Filters_16_32' for inference...\n",
      "Using 50 samples for prediction testing.\n",
      "Load Keras Model \n",
      "Adding Conv2DLayer (kernel: (3, 3, 3, 16), stride: (1, 1), padding: same)\n",
      "Adding ReLULayer\n",
      "Adding MaxPooling2DLayer (pool_size: (2, 2), stride: (2, 2))\n",
      "Adding Conv2DLayer (kernel: (3, 3, 16, 32), stride: (1, 1), padding: same)\n",
      "Adding ReLULayer\n",
      "Adding MaxPooling2DLayer (pool_size: (2, 2), stride: (2, 2))\n",
      "Adding GlobalAveragePooling2DLayer\n",
      "Adding Dense Layer(weight: (32, 128))\n",
      "Adding ReLu\n",
      "Adding Dense Layer(weight: (128, 10))\n",
      "Adding SoftMax\n",
      "Keras Prediction : \n",
      "\n",
      "Keras F1-Score: 0.4990\n",
      "CNN Scratch Prediction : \n",
      "\n",
      "Starting Scratch Prediction for 'B1_Filters_16_32' on 50 samples:\n",
      "Processing: 50/50 (100.0%)\n",
      "Batch prediction complete for 'B1_Filters_16_32'.\n",
      "Total time: 5.73 seconds (0.115 sec/sample).\n",
      "Output array shape: (50, 10)\n",
      "\n",
      "Scratch F1-Score: 0.4990\n",
      "F1-Score Difference: 0.000000\n",
      "Label Match Ratio: 1.0000\n",
      "Mean Absolute Probability Difference: 0.000000\n",
      "Status: Success - Results Closely Match\n",
      "Finished processing Model: B1_Filters_16_32\n",
      "\n",
      "Test Forward Prop for Model 5/11\n",
      "\n",
      "Processing Model: B2_Filters_32_64 (from group: B_Banyak_Filter)\n",
      "Reconstructing Keras model 'B2_Filters_32_64' for inference...\n",
      "Using 50 samples for prediction testing.\n",
      "Load Keras Model \n",
      "Adding Conv2DLayer (kernel: (3, 3, 3, 32), stride: (1, 1), padding: same)\n",
      "Adding ReLULayer\n",
      "Adding MaxPooling2DLayer (pool_size: (2, 2), stride: (2, 2))\n",
      "Adding Conv2DLayer (kernel: (3, 3, 32, 64), stride: (1, 1), padding: same)\n",
      "Adding ReLULayer\n",
      "Adding MaxPooling2DLayer (pool_size: (2, 2), stride: (2, 2))\n",
      "Adding GlobalAveragePooling2DLayer\n",
      "Adding Dense Layer(weight: (64, 128))\n",
      "Adding ReLu\n",
      "Adding Dense Layer(weight: (128, 10))\n",
      "Adding SoftMax\n",
      "Keras Prediction : \n",
      "\n",
      "Keras F1-Score: 0.4673\n",
      "CNN Scratch Prediction : \n",
      "\n",
      "Starting Scratch Prediction for 'B2_Filters_32_64' on 50 samples:\n",
      "Processing: 50/50 (100.0%)\n",
      "Batch prediction complete for 'B2_Filters_32_64'.\n",
      "Total time: 11.57 seconds (0.231 sec/sample).\n",
      "Output array shape: (50, 10)\n",
      "\n",
      "Scratch F1-Score: 0.4673\n",
      "F1-Score Difference: 0.000000\n",
      "Label Match Ratio: 1.0000\n",
      "Mean Absolute Probability Difference: 0.000000\n",
      "Status: Success - Results Closely Match\n",
      "Finished processing Model: B2_Filters_32_64\n",
      "\n",
      "Test Forward Prop for Model 6/11\n",
      "\n",
      "Processing Model: B3_Filters_64_128 (from group: B_Banyak_Filter)\n",
      "Reconstructing Keras model 'B3_Filters_64_128' for inference...\n",
      "Using 50 samples for prediction testing.\n",
      "Load Keras Model \n",
      "Adding Conv2DLayer (kernel: (3, 3, 3, 64), stride: (1, 1), padding: same)\n",
      "Adding ReLULayer\n",
      "Adding MaxPooling2DLayer (pool_size: (2, 2), stride: (2, 2))\n",
      "Adding Conv2DLayer (kernel: (3, 3, 64, 128), stride: (1, 1), padding: same)\n",
      "Adding ReLULayer\n",
      "Adding MaxPooling2DLayer (pool_size: (2, 2), stride: (2, 2))\n",
      "Adding GlobalAveragePooling2DLayer\n",
      "Adding Dense Layer(weight: (128, 128))\n",
      "Adding ReLu\n",
      "Adding Dense Layer(weight: (128, 10))\n",
      "Adding SoftMax\n",
      "Keras Prediction : \n",
      "\n",
      "Keras F1-Score: 0.5992\n",
      "CNN Scratch Prediction : \n",
      "\n",
      "Starting Scratch Prediction for 'B3_Filters_64_128' on 50 samples:\n",
      "Processing: 50/50 (100.0%)\n",
      "Batch prediction complete for 'B3_Filters_64_128'.\n",
      "Total time: 25.51 seconds (0.510 sec/sample).\n",
      "Output array shape: (50, 10)\n",
      "\n",
      "Scratch F1-Score: 0.5992\n",
      "F1-Score Difference: 0.000000\n",
      "Label Match Ratio: 1.0000\n",
      "Mean Absolute Probability Difference: 0.000000\n",
      "Status: Success - Results Closely Match\n",
      "Finished processing Model: B3_Filters_64_128\n",
      "\n",
      "Test Forward Prop for Model 7/11\n",
      "\n",
      "Processing Model: C1_Kernel_2x2 (from group: C_Ukuran_Filter)\n",
      "Reconstructing Keras model 'C1_Kernel_2x2' for inference...\n",
      "Using 50 samples for prediction testing.\n",
      "Load Keras Model \n",
      "Adding Conv2DLayer (kernel: (2, 2, 3, 64), stride: (1, 1), padding: same)\n",
      "Adding ReLULayer\n",
      "Adding MaxPooling2DLayer (pool_size: (2, 2), stride: (2, 2))\n",
      "Adding Conv2DLayer (kernel: (2, 2, 64, 64), stride: (1, 1), padding: same)\n",
      "Adding ReLULayer\n",
      "Adding MaxPooling2DLayer (pool_size: (2, 2), stride: (2, 2))\n",
      "Adding GlobalAveragePooling2DLayer\n",
      "Adding Dense Layer(weight: (64, 128))\n",
      "Adding ReLu\n",
      "Adding Dense Layer(weight: (128, 10))\n",
      "Adding SoftMax\n",
      "Keras Prediction : \n",
      "\n",
      "Keras F1-Score: 0.4458\n",
      "CNN Scratch Prediction : \n",
      "\n",
      "Starting Scratch Prediction for 'C1_Kernel_2x2' on 50 samples:\n",
      "Processing: 50/50 (100.0%)\n",
      "Batch prediction complete for 'C1_Kernel_2x2'.\n",
      "Total time: 19.22 seconds (0.384 sec/sample).\n",
      "Output array shape: (50, 10)\n",
      "\n",
      "Scratch F1-Score: 0.4166\n",
      "F1-Score Difference: 0.029206\n",
      "Label Match Ratio: 0.7400\n",
      "Mean Absolute Probability Difference: 0.035870\n",
      "Status: WARNING - Significant Difference in Results\n",
      "Finished processing Model: C1_Kernel_2x2\n",
      "\n",
      "Test Forward Prop for Model 8/11\n",
      "\n",
      "Processing Model: C2_Kernel_3x3 (from group: C_Ukuran_Filter)\n",
      "Reconstructing Keras model 'C2_Kernel_3x3' for inference...\n",
      "Using 50 samples for prediction testing.\n",
      "Load Keras Model \n",
      "Adding Conv2DLayer (kernel: (3, 3, 3, 64), stride: (1, 1), padding: same)\n",
      "Adding ReLULayer\n",
      "Adding MaxPooling2DLayer (pool_size: (2, 2), stride: (2, 2))\n",
      "Adding Conv2DLayer (kernel: (3, 3, 64, 64), stride: (1, 1), padding: same)\n",
      "Adding ReLULayer\n",
      "Adding MaxPooling2DLayer (pool_size: (2, 2), stride: (2, 2))\n",
      "Adding GlobalAveragePooling2DLayer\n",
      "Adding Dense Layer(weight: (64, 128))\n",
      "Adding ReLu\n",
      "Adding Dense Layer(weight: (128, 10))\n",
      "Adding SoftMax\n",
      "Keras Prediction : \n",
      "\n",
      "Keras F1-Score: 0.4740\n",
      "CNN Scratch Prediction : \n",
      "\n",
      "Starting Scratch Prediction for 'C2_Kernel_3x3' on 50 samples:\n",
      "Processing: 50/50 (100.0%)\n",
      "Batch prediction complete for 'C2_Kernel_3x3'.\n",
      "Total time: 21.27 seconds (0.425 sec/sample).\n",
      "Output array shape: (50, 10)\n",
      "\n",
      "Scratch F1-Score: 0.4740\n",
      "F1-Score Difference: 0.000000\n",
      "Label Match Ratio: 1.0000\n",
      "Mean Absolute Probability Difference: 0.000000\n",
      "Status: Success - Results Closely Match\n",
      "Finished processing Model: C2_Kernel_3x3\n",
      "\n",
      "Test Forward Prop for Model 9/11\n",
      "\n",
      "Processing Model: C3_Kernel_5x5 (from group: C_Ukuran_Filter)\n",
      "Reconstructing Keras model 'C3_Kernel_5x5' for inference...\n",
      "Using 50 samples for prediction testing.\n",
      "Load Keras Model \n",
      "Adding Conv2DLayer (kernel: (5, 5, 3, 64), stride: (1, 1), padding: same)\n",
      "Adding ReLULayer\n",
      "Adding MaxPooling2DLayer (pool_size: (2, 2), stride: (2, 2))\n",
      "Adding Conv2DLayer (kernel: (5, 5, 64, 64), stride: (1, 1), padding: same)\n",
      "Adding ReLULayer\n",
      "Adding MaxPooling2DLayer (pool_size: (2, 2), stride: (2, 2))\n",
      "Adding GlobalAveragePooling2DLayer\n",
      "Adding Dense Layer(weight: (64, 128))\n",
      "Adding ReLu\n",
      "Adding Dense Layer(weight: (128, 10))\n",
      "Adding SoftMax\n",
      "Keras Prediction : \n",
      "\n",
      "Keras F1-Score: 0.6157\n",
      "CNN Scratch Prediction : \n",
      "\n",
      "Starting Scratch Prediction for 'C3_Kernel_5x5' on 50 samples:\n",
      "Processing: 50/50 (100.0%)\n",
      "Batch prediction complete for 'C3_Kernel_5x5'.\n",
      "Total time: 20.55 seconds (0.411 sec/sample).\n",
      "Output array shape: (50, 10)\n",
      "\n",
      "Scratch F1-Score: 0.6157\n",
      "F1-Score Difference: 0.000000\n",
      "Label Match Ratio: 1.0000\n",
      "Mean Absolute Probability Difference: 0.000000\n",
      "Status: Success - Results Closely Match\n",
      "Finished processing Model: C3_Kernel_5x5\n",
      "\n",
      "Test Forward Prop for Model 10/11\n",
      "\n",
      "Processing Model: D1_Pooling_Max (from group: D_Jenis_Pooling)\n",
      "Reconstructing Keras model 'D1_Pooling_Max' for inference...\n",
      "Using 50 samples for prediction testing.\n",
      "Load Keras Model \n",
      "Adding Conv2DLayer (kernel: (3, 3, 3, 32), stride: (1, 1), padding: same)\n",
      "Adding ReLULayer\n",
      "Adding MaxPooling2DLayer (pool_size: (2, 2), stride: (2, 2))\n",
      "Adding Conv2DLayer (kernel: (3, 3, 32, 64), stride: (1, 1), padding: same)\n",
      "Adding ReLULayer\n",
      "Adding MaxPooling2DLayer (pool_size: (2, 2), stride: (2, 2))\n",
      "Adding GlobalAveragePooling2DLayer\n",
      "Adding Dense Layer(weight: (64, 128))\n",
      "Adding ReLu\n",
      "Adding Dense Layer(weight: (128, 10))\n",
      "Adding SoftMax\n",
      "Keras Prediction : \n",
      "\n",
      "Keras F1-Score: 0.4978\n",
      "CNN Scratch Prediction : \n",
      "\n",
      "Starting Scratch Prediction for 'D1_Pooling_Max' on 50 samples:\n",
      "Processing: 50/50 (100.0%)\n",
      "Batch prediction complete for 'D1_Pooling_Max'.\n",
      "Total time: 12.01 seconds (0.240 sec/sample).\n",
      "Output array shape: (50, 10)\n",
      "\n",
      "Scratch F1-Score: 0.4978\n",
      "F1-Score Difference: 0.000000\n",
      "Label Match Ratio: 1.0000\n",
      "Mean Absolute Probability Difference: 0.000000\n",
      "Status: Success - Results Closely Match\n",
      "Finished processing Model: D1_Pooling_Max\n",
      "\n",
      "Test Forward Prop for Model 11/11\n",
      "\n",
      "Processing Model: D2_Pooling_Avg (from group: D_Jenis_Pooling)\n",
      "Reconstructing Keras model 'D2_Pooling_Avg' for inference...\n",
      "Using 50 samples for prediction testing.\n",
      "Load Keras Model \n",
      "Adding Conv2DLayer (kernel: (3, 3, 3, 32), stride: (1, 1), padding: same)\n",
      "Adding ReLULayer\n",
      "WARN: Layer of type AveragePooling2D aren't supported.\n",
      "Adding Conv2DLayer (kernel: (3, 3, 32, 64), stride: (1, 1), padding: same)\n",
      "Adding ReLULayer\n",
      "WARN: Layer of type AveragePooling2D aren't supported.\n",
      "Adding GlobalAveragePooling2DLayer\n",
      "Adding Dense Layer(weight: (64, 128))\n",
      "Adding ReLu\n",
      "Adding Dense Layer(weight: (128, 10))\n",
      "Adding SoftMax\n",
      "Keras Prediction : \n",
      "\n",
      "Keras F1-Score: 0.4302\n",
      "CNN Scratch Prediction : \n",
      "\n",
      "Starting Scratch Prediction for 'D2_Pooling_Avg' on 50 samples:\n",
      "Processing: 50/50 (100.0%)\n",
      "Batch prediction complete for 'D2_Pooling_Avg'.\n",
      "Total time: 21.37 seconds (0.427 sec/sample).\n",
      "Output array shape: (50, 10)\n",
      "\n",
      "Scratch F1-Score: 0.3412\n",
      "F1-Score Difference: 0.089029\n",
      "Label Match Ratio: 0.6000\n",
      "Mean Absolute Probability Difference: 0.044508\n",
      "Status: WARNING - Significant Difference in Results\n",
      "Finished processing Model: D2_Pooling_Avg\n",
      "\n",
      "\n",
      "All forward propagation comparisons finished.\n"
     ]
    }
   ],
   "source": [
    "# Run the Comparison\n",
    "\n",
    "NUM_SAMPLES_FOR_FWD_PROP_TEST = 50\n",
    "\n",
    "if 'training_configurations' not in locals() or not training_configurations:\n",
    "    print(\"ERROR: training configurations is empty\")\n",
    "    forward_prop_test_configs_adapted = []\n",
    "else:\n",
    "    forward_prop_test_configs_adapted = []\n",
    "    for train_config_item in training_configurations:\n",
    "        forward_prop_test_configs_adapted.append({\n",
    "            'model_name_tag': train_config_item['name'],\n",
    "            'experiment_group_for_weights': train_config_item['experiment_group'], \n",
    "            'architecture_config': train_config_item['params'] \n",
    "        })\n",
    "    print(f\"Total configurations adapted for forward-prop test: {len(forward_prop_test_configs_adapted)}\")\n",
    "\n",
    "\n",
    "\n",
    "all_comparison_results = []\n",
    "num_models_to_process_fp = len(forward_prop_test_configs_adapted) \n",
    "\n",
    "if num_models_to_process_fp > 0:\n",
    "    print(f\"\\nStarting forward propagation comparison for {num_models_to_process_fp} model configurations\")\n",
    "\n",
    "    for i, model_config_entry in enumerate(forward_prop_test_configs_adapted):\n",
    "        print(f\"\\nTest Forward Prop for Model {i+1}/{num_models_to_process_fp}\")\n",
    "        \n",
    "        result_dict = run_forward_propagation_comparison(\n",
    "            model_name_tag= model_config_entry['model_name_tag'],\n",
    "            keras_architecture_config= model_config_entry['architecture_config'],\n",
    "            base_weights_dir_to_load= RESULTS_BASE_DIR,\n",
    "            experiment_group_for_weights= model_config_entry['experiment_group_for_weights'],\n",
    "            x_test_full_keras_data= x_test_keras,\n",
    "            y_test_full_keras_data= y_test_keras,\n",
    "            input_shape_param= input_shape_global, \n",
    "            num_classes_param= num_classes_global,    \n",
    "            num_samples_to_test= NUM_SAMPLES_FOR_FWD_PROP_TEST\n",
    "        )\n",
    "        all_comparison_results.append(result_dict)\n",
    "    print(\"\\n\\nAll forward propagation comparisons finished.\")\n",
    "else:\n",
    "    print(\"No model configurations available to test for forward propagation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "37a6be8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of Forward Propagation Comparison Results\n",
      "           model_name  f1_keras  f1_scratch\n",
      "0      A1_1_ConvBlock  0.440476    0.440476\n",
      "1     A2_2_ConvBlocks  0.476779    0.476779\n",
      "2     A3_3_ConvBlocks  0.691220    0.691220\n",
      "3    B1_Filters_16_32  0.499015    0.499015\n",
      "4    B2_Filters_32_64  0.467274    0.467274\n",
      "5   B3_Filters_64_128  0.599246    0.599246\n",
      "6       C1_Kernel_2x2  0.445812    0.416606\n",
      "7       C2_Kernel_3x3  0.473990    0.473990\n",
      "8       C3_Kernel_5x5  0.615709    0.615709\n",
      "9      D1_Pooling_Max  0.497829    0.497829\n",
      "10     D2_Pooling_Avg  0.430238    0.341209\n"
     ]
    }
   ],
   "source": [
    "if all_comparison_results:\n",
    "    df_results = pd.DataFrame(all_comparison_results)\n",
    "    column_order = ['model_name',  'f1_keras', 'f1_scratch']\n",
    "    for col in column_order:\n",
    "        if col not in df_results.columns:\n",
    "            df_results[col] = None      \n",
    "    df_results = df_results[column_order] \n",
    "    \n",
    "    print(\"\\nSummary of Forward Propagation Comparison Results\")\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', 120) \n",
    "    pd.set_option('display.float_format', '{:.6f}'.format)\n",
    "    \n",
    "    print(df_results)\n",
    "else:\n",
    "    print(\"No comparison results to display.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
